{"cells":[{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:46:23.603500Z","iopub.status.busy":"2023-12-14T14:46:23.603076Z","iopub.status.idle":"2023-12-14T14:46:23.621097Z","shell.execute_reply":"2023-12-14T14:46:23.620140Z","shell.execute_reply.started":"2023-12-14T14:46:23.603467Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","import PIL.Image\n","import PIL\n","PIL.Image.MAX_IMAGE_PIXELS = None\n","\n","# Load the metadata from CSV files\n","train_metadata = pd.read_csv('train.csv')\n","test_metadata = pd.read_csv('test.csv')\n","\n","\n","#Filter for rows where \"is_tma\" is False\n","train_metadata = train_metadata[train_metadata['is_tma'] == False]\n","\n","\n","# Split the training data into training and validation sets\n","train_data, val_data = train_test_split(train_metadata, test_size=0.1, random_state=42)\n","\n","# Define the paths to your image files (change to actual)\n","train_image_paths = ['train_crops' + str(img_id) + '_.png' for img_id in train_data['image_id']]\n","val_image_paths = ['train_crops' + str(img_id) + '.png' for img_id in val_data['image_id']]\n","test_image_paths = ['test_images/' + str(img_id) + '.png' for img_id in test_metadata['image_id']]"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:46:27.878866Z","iopub.status.busy":"2023-12-14T14:46:27.878249Z","iopub.status.idle":"2023-12-14T14:49:10.359763Z","shell.execute_reply":"2023-12-14T14:49:10.358890Z","shell.execute_reply.started":"2023-12-14T14:46:27.878834Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if is_sparse(pd_dtype):\n","/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if is_sparse(pd_dtype):\n","/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"]}],"source":["# Define a function to load and preprocess images\n","def load_and_preprocess_image(image_path):\n","    img = Image.open(image_path)\n","    img = img.resize((224, 224))  # Resize to desired dimensions\n","    img = np.array(img)  # Convert to numpy array\n","    # Apply any further preprocessing steps if needed\n","    return img\n","\n","# Apply preprocessing to all image paths\n","train_images = [load_and_preprocess_image(path) for path in train_image_paths]\n","val_images = [load_and_preprocess_image(path) for path in val_image_paths]\n","test_images = [load_and_preprocess_image(path) for path in test_image_paths]\n","\n","# Convert labels to one-hot encoding\n","from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","train_labels = label_encoder.fit_transform(train_data['label'])\n","val_labels = label_encoder.transform(val_data['label'])\n","# Note: Keep label_encoder for later use in decoding predictions\n","\n","\n","# Define a data generator for augmentation\n","train_datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    zoom_range=0.3,\n","    horizontal_flip=False,\n","    vertical_flip=False,\n","    fill_mode='nearest'\n",")\n","\n","\n","\n","# Define a data generator function\n","def data_generator(images, labels, batch_size, data_augmentation=True):\n","    while True:\n","        # Generate random indices for the batch\n","        indices = np.random.choice(len(images), size=batch_size, replace=False)\n","        batch_images = []\n","        batch_labels = []\n","        \n","        for idx in indices:\n","            # Load and preprocess the image\n","            image = load_and_preprocess_image(images[idx])\n","            label = labels[idx]\n","            \n","            # Apply data augmentation (if enabled)\n","            if data_augmentation:\n","                image = train_datagen.random_transform(image)\n","            \n","            batch_images.append(image)\n","            batch_labels.append(label)\n","        \n","        yield np.array(batch_images), np.array(batch_labels)\n","\n","# Define batch size\n","batch_size = 32\n","\n","# Create data generators for training and validation sets\n","train_generator = data_generator(train_image_paths, train_labels, batch_size)\n","val_generator = data_generator(val_image_paths, val_labels, batch_size, data_augmentation=False)\n","\n","# Check the data generator\n","batch_images, batch_labels = next(train_generator)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:39:13.904579Z","iopub.status.busy":"2023-12-14T14:39:13.904216Z","iopub.status.idle":"2023-12-14T14:39:13.909589Z","shell.execute_reply":"2023-12-14T14:39:13.908580Z","shell.execute_reply.started":"2023-12-14T14:39:13.904550Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Input, AveragePooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.models import Model\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:39:17.511600Z","iopub.status.busy":"2023-12-14T14:39:17.511225Z","iopub.status.idle":"2023-12-14T14:39:19.794459Z","shell.execute_reply":"2023-12-14T14:39:19.793597Z","shell.execute_reply.started":"2023-12-14T14:39:17.511568Z"},"trusted":true},"outputs":[],"source":["rsntBase = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:39:21.660200Z","iopub.status.busy":"2023-12-14T14:39:21.659842Z","iopub.status.idle":"2023-12-14T14:39:22.214041Z","shell.execute_reply":"2023-12-14T14:39:22.213046Z","shell.execute_reply.started":"2023-12-14T14:39:21.660172Z"},"trusted":true},"outputs":[],"source":["# Adding own classification layers on top\n","model = tf.keras.Sequential([\n","    rsntBase,\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(6, activation='softmax')\n","])\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:39:26.365524Z","iopub.status.busy":"2023-12-14T14:39:26.365157Z","iopub.status.idle":"2023-12-14T14:39:26.390161Z","shell.execute_reply":"2023-12-14T14:39:26.388928Z","shell.execute_reply.started":"2023-12-14T14:39:26.365493Z"},"trusted":true},"outputs":[],"source":["# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:49:38.234252Z","iopub.status.busy":"2023-12-14T14:49:38.233523Z","iopub.status.idle":"2023-12-14T14:51:59.997200Z","shell.execute_reply":"2023-12-14T14:51:59.996411Z","shell.execute_reply.started":"2023-12-14T14:49:38.234220Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","13/13 [==============================] - 56s 724ms/step - loss: 11.2725 - accuracy: 0.2927 - val_loss: 529.7405 - val_accuracy: 0.3883\n","Epoch 2/20\n","13/13 [==============================] - 4s 342ms/step - loss: 1.6946 - accuracy: 0.3756 - val_loss: 893.9791 - val_accuracy: 0.3883\n","Epoch 3/20\n","13/13 [==============================] - 4s 345ms/step - loss: 1.7874 - accuracy: 0.4098 - val_loss: 273.4258 - val_accuracy: 0.3883\n","Epoch 4/20\n","13/13 [==============================] - 5s 349ms/step - loss: 1.6497 - accuracy: 0.4049 - val_loss: 110.3719 - val_accuracy: 0.3883\n","Epoch 5/20\n","13/13 [==============================] - 5s 351ms/step - loss: 1.6020 - accuracy: 0.3805 - val_loss: 85.7609 - val_accuracy: 0.3883\n","Epoch 6/20\n","13/13 [==============================] - 5s 354ms/step - loss: 1.5865 - accuracy: 0.4195 - val_loss: 6.2272 - val_accuracy: 0.3883\n","Epoch 7/20\n","13/13 [==============================] - 5s 356ms/step - loss: 1.5329 - accuracy: 0.4268 - val_loss: 3.1787 - val_accuracy: 0.3883\n","Epoch 8/20\n","13/13 [==============================] - 5s 355ms/step - loss: 1.5205 - accuracy: 0.4244 - val_loss: 2.9204 - val_accuracy: 0.3883\n","Epoch 9/20\n","13/13 [==============================] - 5s 353ms/step - loss: 1.4964 - accuracy: 0.4268 - val_loss: 5.0615 - val_accuracy: 0.3883\n","Epoch 10/20\n","13/13 [==============================] - 4s 348ms/step - loss: 1.4708 - accuracy: 0.4366 - val_loss: 3.0785 - val_accuracy: 0.3883\n","Epoch 11/20\n","13/13 [==============================] - 4s 346ms/step - loss: 1.4703 - accuracy: 0.4463 - val_loss: 1.5191 - val_accuracy: 0.3883\n","Epoch 12/20\n","13/13 [==============================] - 4s 346ms/step - loss: 1.3075 - accuracy: 0.4707 - val_loss: 1.6303 - val_accuracy: 0.3883\n","Epoch 13/20\n","13/13 [==============================] - 4s 342ms/step - loss: 1.2705 - accuracy: 0.4610 - val_loss: 1.6724 - val_accuracy: 0.2039\n","Epoch 14/20\n","13/13 [==============================] - 4s 341ms/step - loss: 1.2228 - accuracy: 0.4829 - val_loss: 1.7211 - val_accuracy: 0.1942\n","Epoch 15/20\n","13/13 [==============================] - 4s 339ms/step - loss: 1.1997 - accuracy: 0.4951 - val_loss: 1.7298 - val_accuracy: 0.1942\n","Epoch 16/20\n","13/13 [==============================] - 4s 340ms/step - loss: 1.1447 - accuracy: 0.5098 - val_loss: 1.7092 - val_accuracy: 0.1942\n","Epoch 17/20\n","13/13 [==============================] - 4s 339ms/step - loss: 1.1001 - accuracy: 0.5415 - val_loss: 1.6592 - val_accuracy: 0.1942\n","Epoch 18/20\n","13/13 [==============================] - 4s 339ms/step - loss: 1.0348 - accuracy: 0.5390 - val_loss: 1.6912 - val_accuracy: 0.1942\n","Epoch 19/20\n","13/13 [==============================] - 4s 341ms/step - loss: 0.9292 - accuracy: 0.6098 - val_loss: 1.7009 - val_accuracy: 0.1942\n","Epoch 20/20\n","13/13 [==============================] - 4s 341ms/step - loss: 0.9230 - accuracy: 0.5951 - val_loss: 1.6572 - val_accuracy: 0.3786\n"]}],"source":["# Convert images and labels to numpy arrays\n","\n","\n","train_images = np.array(train_images)\n","val_images = np.array(val_images)\n","test_images = np.array(test_images)\n","train_labels = np.array(train_labels)\n","val_labels = np.array(val_labels)\n","\n","# Normalize pixel values to be between 0 and 1\n","train_images = train_images / 255.0\n","val_images = val_images / 255.0\n","test_images = test_images / 255.0\n","\n","# Train the model\n","history = model.fit(train_images, train_labels, epochs=20, validation_data=(val_images, val_labels))\n","\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:56:28.396619Z","iopub.status.busy":"2023-12-14T14:56:28.396268Z","iopub.status.idle":"2023-12-14T14:56:28.478048Z","shell.execute_reply":"2023-12-14T14:56:28.477057Z","shell.execute_reply.started":"2023-12-14T14:56:28.396594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 25ms/step\n","['HGSC']\n"]}],"source":["# Make predictions on the test set\n","predictions = model.predict(test_images)\n","\n","# Convert the predicted probabilities to class labels\n","predicted_labels = [np.argmax(prediction) for prediction in predictions]\n","\n","# Decode the predicted labels using the label_encoder\n","predicted_subtypes = label_encoder.inverse_transform(predicted_labels)\n","\n","# Print the predicted subtypes\n","print(predicted_subtypes)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T14:56:32.093996Z","iopub.status.busy":"2023-12-14T14:56:32.093143Z","iopub.status.idle":"2023-12-14T14:56:32.101547Z","shell.execute_reply":"2023-12-14T14:56:32.100594Z","shell.execute_reply.started":"2023-12-14T14:56:32.093955Z"},"trusted":true},"outputs":[],"source":["# Create a DataFrame with the image IDs and predicted subtypes\n","submission_df = pd.DataFrame({'image_id': test_metadata['image_id'], 'predicted_subtype': predicted_subtypes})\n","\n","# Save the DataFrame to a CSV file\n","submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":6924515,"sourceId":45867,"sourceType":"competition"},{"datasetId":4160400,"sourceId":7194170,"sourceType":"datasetVersion"},{"datasetId":4165723,"sourceId":7201547,"sourceType":"datasetVersion"}],"dockerImageVersionId":30579,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
